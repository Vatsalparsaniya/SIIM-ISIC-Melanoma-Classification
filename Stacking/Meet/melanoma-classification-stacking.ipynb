{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nfrom scipy.stats import rankdata\nimport warnings\n\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import StackingClassifier\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\n\nwarnings.simplefilter('ignore')\n\nSEED = 2020\n\ndef seed_everything(SEED):\n    np.random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n\nseed_everything(SEED)","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oof_base = pd.read_csv('../input/melanoma-classification-submissions/oof_base.csv')\n# test_base = pd.read_csv('../input/melanoma-classification-submissions/test_base.csv')\n\noof_base = pd.read_csv('../input/melanoma-classification-submissions/Ensemble_oof_base.csv')\ntest_base = pd.read_csv('../input/melanoma-classification-submissions/Ensemble_test_base.csv')\n\noof1 = pd.read_csv('../input/melanoma-classification-submissions/oofrank_stacking_0.9556103556665613.csv')\ntest1 = pd.read_csv('../input/melanoma-classification-submissions/TESTPREDS_RANK_STACKING_0.9556103556665613.csv')\n\nif 'target' in oof_base.columns:\n    oof_base = oof_base.drop(['target'],axis=1)\nif 'tfrecord' in oof_base.columns:\n    oof_base = oof_base.drop(['tfrecord'],axis=1)\n\ntrain_df = pd.read_csv('../input/melanoma-classification-submissions/train_coded.csv').iloc[:,:-3]\ntest_df = pd.read_csv('../input/melanoma-classification-submissions/test_coded.csv').iloc[:,:-3]\n\ntrain_df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"     image_name  tfrecord  sex_female  sex_male  age_approx  \\\n0  ISIC_0015719         0           1         0   -0.269395   \n1  ISIC_0052212         6           1         0    0.078659   \n2  ISIC_0068279         0           1         0   -0.269395   \n3  ISIC_0074268        11           1         0    0.426713   \n4  ISIC_0074311         1           1         0   -0.617449   \n\n   anatom_site_head/neck  anatom_site_lower extremity  \\\n0                      0                            0   \n1                      0                            1   \n2                      1                            0   \n3                      0                            0   \n4                      0                            1   \n\n   anatom_site_oral/genital  anatom_site_palms/soles  anatom_site_torso  \\\n0                         0                        0                  0   \n1                         0                        0                  0   \n2                         0                        0                  0   \n3                         0                        0                  0   \n4                         0                        0                  0   \n\n   anatom_site_upper extremity  target  \n0                            1       0  \n1                            0       0  \n2                            0       0  \n3                            1       0  \n4                            0       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tfrecord</th>\n      <th>sex_female</th>\n      <th>sex_male</th>\n      <th>age_approx</th>\n      <th>anatom_site_head/neck</th>\n      <th>anatom_site_lower extremity</th>\n      <th>anatom_site_oral/genital</th>\n      <th>anatom_site_palms/soles</th>\n      <th>anatom_site_torso</th>\n      <th>anatom_site_upper extremity</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015719</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.269395</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052212</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.078659</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0068279</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.269395</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0074268</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.426713</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074311</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.617449</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_base.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"     image_name    pred_1    pred_2    pred_3    pred_4    pred_5    pred_6\n0  ISIC_0052212  0.196309  0.014284  0.191025  0.391115  0.057988  0.167212\n1  ISIC_0080817  0.882696  0.189913  0.874424  0.843217  0.770537  0.812890\n2  ISIC_0080512  0.165721  0.009689  0.103429  0.391370  0.145995  0.394959\n3  ISIC_0078712  0.735265  0.114964  0.704611  0.700642  0.703762  0.350422\n4  ISIC_0086349  0.591158  0.044780  0.570354  0.483870  0.516813  0.419047","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>pred_1</th>\n      <th>pred_2</th>\n      <th>pred_3</th>\n      <th>pred_4</th>\n      <th>pred_5</th>\n      <th>pred_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052212</td>\n      <td>0.196309</td>\n      <td>0.014284</td>\n      <td>0.191025</td>\n      <td>0.391115</td>\n      <td>0.057988</td>\n      <td>0.167212</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0080817</td>\n      <td>0.882696</td>\n      <td>0.189913</td>\n      <td>0.874424</td>\n      <td>0.843217</td>\n      <td>0.770537</td>\n      <td>0.812890</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0080512</td>\n      <td>0.165721</td>\n      <td>0.009689</td>\n      <td>0.103429</td>\n      <td>0.391370</td>\n      <td>0.145995</td>\n      <td>0.394959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0078712</td>\n      <td>0.735265</td>\n      <td>0.114964</td>\n      <td>0.704611</td>\n      <td>0.700642</td>\n      <td>0.703762</td>\n      <td>0.350422</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0086349</td>\n      <td>0.591158</td>\n      <td>0.044780</td>\n      <td>0.570354</td>\n      <td>0.483870</td>\n      <td>0.516813</td>\n      <td>0.419047</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_base.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"     image_name  target_1  target_2  target_3  target_4  target_5  target_6\n0  ISIC_0052060  0.176193  0.007751  0.171702  0.243763  0.197932  0.333227\n1  ISIC_0052349  0.169651  0.006849  0.125155  0.127541  0.236472  0.197869\n2  ISIC_0058510  0.105116  0.004922  0.118434  0.055935  0.060544  0.177336\n3  ISIC_0073313  0.143915  0.008863  0.189443  0.196783  0.183630  0.021034\n4  ISIC_0073502  0.556200  0.052100  0.529352  0.521823  0.626869  0.432754","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target_1</th>\n      <th>target_2</th>\n      <th>target_3</th>\n      <th>target_4</th>\n      <th>target_5</th>\n      <th>target_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.176193</td>\n      <td>0.007751</td>\n      <td>0.171702</td>\n      <td>0.243763</td>\n      <td>0.197932</td>\n      <td>0.333227</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.169651</td>\n      <td>0.006849</td>\n      <td>0.125155</td>\n      <td>0.127541</td>\n      <td>0.236472</td>\n      <td>0.197869</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.105116</td>\n      <td>0.004922</td>\n      <td>0.118434</td>\n      <td>0.055935</td>\n      <td>0.060544</td>\n      <td>0.177336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.143915</td>\n      <td>0.008863</td>\n      <td>0.189443</td>\n      <td>0.196783</td>\n      <td>0.183630</td>\n      <td>0.021034</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.556200</td>\n      <td>0.052100</td>\n      <td>0.529352</td>\n      <td>0.521823</td>\n      <td>0.626869</td>\n      <td>0.432754</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_base_1 = oof_base.copy()\ntest_base_1 = test_base.copy()\n\noof_base_1['pred_2'] = rankdata(oof_base_1['pred_2'])/rankdata(oof_base_1['pred_2']).max()\ntest_base_1['target_2'] = rankdata(test_base_1['target_2'])/rankdata(test_base_1['target_2']).max()\n\noof1.pred = rankdata(oof1.pred)/rankdata(oof1.pred).max()\ntest1.target = rankdata(test1.target)/rankdata(test1.target).max()\n\noof_base_1['pred_7'] = oof_base_1.merge(oof1[['image_name','pred']],on='image_name',suffixes=('_6','_7'))['pred']\ntest_base_1['target_7'] = test_base_1.merge(test1,on='image_name',suffixes=('_6','_7'))['target']\n\noof_target_1 = oof_base_1.merge(train_df[['image_name','target']],on='image_name')[['target']]\n\nfor col in oof_base_1.columns[1:]:\n    print(f'{col} AUC: {roc_auc_score(oof_target_1,oof_base_1[col])}')\n    \norder = [3,4,1,5,2,6]\n\noof_trend = []\ntest_trend = []\n\nfor i in range(len(order)-1):\n    oof_trend.append(oof_base_1[f'pred_{order[i]}']-oof_base_1[f'pred_{order[i+1]}'])\n    test_trend.append(test_base_1[f'target_{order[i]}']-test_base_1[f'target_{order[i+1]}'])\n\nweight = 1\nprint(\"\\nWeight: \",weight)\noof_base_1['avg_diff'] = np.mean(oof_trend,axis=0)\ntest_base_1['avg_diff'] = np.mean(test_trend,axis=0)\n\nprint()\nprint()\ntest_base_new = pd.DataFrame()\ntest_base_new['image_name'] = test_base.image_name\noof_base_new = pd.DataFrame()\noof_base_new['image_name'] = oof_base.image_name\naucs = []\nfor i in range(7):\n    pred_col = i+1\n    oof_base_new[f'pred_{pred_col}'] = oof_base_1.apply(lambda x: (1+weight*x['avg_diff'])*x[f'pred_{pred_col}'] if x['avg_diff']<0 else (1-weight*x['avg_diff'])*x[f'pred_{pred_col}']+x['avg_diff'],axis=1)\n    aucs.append(roc_auc_score(oof_target_1,oof_base_new[f'pred_{pred_col}']))\n    print(f\"pred_{i+1} New AUC: \",aucs[-1])\n    \n    test_base_new[f'target_{pred_col}'] = test_base_1.apply(lambda x: (1+weight*x['avg_diff'])*x[f'target_{pred_col}'] if x['avg_diff']<0 else (1-weight*x['avg_diff'])*x[f'target_{pred_col}']+x['avg_diff'],axis=1)\n    \n# plt.hist(new_sub,bins=100)\n# plt.show()\ntest_base_new.head()","execution_count":14,"outputs":[{"output_type":"stream","text":"pred_1 AUC: 0.9487946045159296\npred_2 AUC: 0.9437367938054374\npred_3 AUC: 0.9517729781018307\npred_4 AUC: 0.9500662530804962\npred_5 AUC: 0.9470354044605709\npred_6 AUC: 0.9321982091916428\npred_7 AUC: 0.9556103556665613\n\nWeight:  1\n\n\npred_1 New AUC:  0.9492002542171515\npred_2 New AUC:  0.9444559536946149\npred_3 New AUC:  0.9516953643640703\npred_4 New AUC:  0.9504170425188746\npred_5 New AUC:  0.9472943759895684\npred_6 New AUC:  0.9362764948671216\npred_7 New AUC:  0.955639246415631\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"     image_name  target_1  target_2  target_3  target_4  target_5  target_6  \\\n0  ISIC_0052060  0.170501  0.093315  0.166155  0.235888  0.191538  0.322462   \n1  ISIC_0052349  0.167184  0.071518  0.123335  0.125686  0.233033  0.194992   \n2  ISIC_0058510  0.103878  0.023126  0.117039  0.055276  0.059831  0.175247   \n3  ISIC_0073313  0.172749  0.156517  0.216744  0.223837  0.211126  0.054008   \n4  ISIC_0073502  0.564774  0.569222  0.538444  0.531061  0.634078  0.443713   \n\n   target_7  \n0  0.323828  \n1  0.111808  \n2  0.138038  \n3  0.150358  \n4  0.543236  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target_1</th>\n      <th>target_2</th>\n      <th>target_3</th>\n      <th>target_4</th>\n      <th>target_5</th>\n      <th>target_6</th>\n      <th>target_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.170501</td>\n      <td>0.093315</td>\n      <td>0.166155</td>\n      <td>0.235888</td>\n      <td>0.191538</td>\n      <td>0.322462</td>\n      <td>0.323828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.167184</td>\n      <td>0.071518</td>\n      <td>0.123335</td>\n      <td>0.125686</td>\n      <td>0.233033</td>\n      <td>0.194992</td>\n      <td>0.111808</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.103878</td>\n      <td>0.023126</td>\n      <td>0.117039</td>\n      <td>0.055276</td>\n      <td>0.059831</td>\n      <td>0.175247</td>\n      <td>0.138038</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.172749</td>\n      <td>0.156517</td>\n      <td>0.216744</td>\n      <td>0.223837</td>\n      <td>0.211126</td>\n      <td>0.054008</td>\n      <td>0.150358</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.564774</td>\n      <td>0.569222</td>\n      <td>0.538444</td>\n      <td>0.531061</td>\n      <td>0.634078</td>\n      <td>0.443713</td>\n      <td>0.543236</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oofrank = pd.DataFrame(dict(\n    image_name = oof_base_new.image_name,\n    pred = oof_base_new.pred_7,\n    target = oof_target_1.values[:,0]\n))\n\ntestrank = pd.DataFrame(dict(\n    image_name = test_base_1.image_name,\n    target = test_base_1.target_7\n))","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oofrank.to_csv(f'oofrank_stacking_{aucs[-1]}.csv',index=False)\ntestrank.to_csv(f'TESTPREDS_RANK_STACKING_{aucs[-1]}.csv',index=False)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# col = 7\n# sub = test_base_new[['image_name']]\n# sub['target'] = test_base_new[f'target_{col}']\n\n# sub.to_csv(f'PROBABILITY_CALIB_{aucs[col-1]}.csv',index=False)\n\n# sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.hist(sub.target,bins=100)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oof_base = oof_base_new.copy()\n# test_base = test_base_new.copy()\n\noof_base = train_df.merge(oof_base,on='image_name')\ntest_base = test_df.merge(test_base,on='image_name')\n\noof_base.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_base.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oof_base = oof_base.merge(train_df[['image_name','target','tfrecord']],on='image_name')\n\ny = oof_base[['target']]\ntfrecord = oof_base[['tfrecord']]\nimage_names = oof_base[['image_name']]\nX = oof_base.drop(['target','tfrecord','image_name'],axis=1)\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_base.drop(['image_name'],axis=1)\n\nX_test.columns = X.columns\n\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# %%time\n\n# clf1 = KNeighborsClassifier(n_neighbors=3)\n# clf2 = RandomForestClassifier(random_state=SEED)\n# clf3 = GaussianNB()\n# lr = LogisticRegression(random_state=SEED)\n# sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n#                           use_probas=True,\n#                           average_probas=False,\n#                           meta_classifier=lr)\n\n# print('5-fold cross validation:\\n')\n\n# for clf, label in zip([clf1, clf2, clf3, sclf], \n#                       ['KNN', \n#                        'Random Forest', \n#                        'Naive Bayes',\n#                        'StackingClassifier']):\n\n#     scores = model_selection.cross_val_score(clf, X, y, cv=5, scoring='roc_auc', n_jobs=-1, verbose=0)\n#     print(\"AUC: %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLDS = 5\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n\ndef crossValidate(X=X,y=y,X_test=X_test,tfrecord=tfrecord,image_names=image_names,\n                  skf=skf,CLF=LogisticRegression,params=dict(n_jobs= -1),\n                  predict_test=False, predict_proba=True):\n    print()\n    print()\n    print(\"#\"*50)\n    print(\"#### CLF: \",CLF)\n    \n    cvScore = []\n    valpreds = []\n    valimagenames = []\n    valtargets = []\n\n    for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n        print(f\"#### FOLD: {fold}\")\n#         print(f\"#### Train idx: {idxT}\")\n#         print(f\"#### Train idx: {idxV}\\n\")\n\n        idxT, idxV = tfrecord.tfrecord.isin(idxT), tfrecord.tfrecord.isin(idxV)\n        \n#         print()\n#         print(\"#### Preparing Training and Validation Datasets\")\n        X_train, y_train = X[idxT], y[idxT]\n        X_val, y_val = X[idxV], y[idxV]\n        \n#         print()\n#         print(\"#### Initializing the Model\")\n        clf = CLF(**params)\n        \n#         print()\n#         print(\"#### Training.....\")\n        clf.fit(X_train,y_train)\n        \n        \n#         print()\n#         print(\"#### Predicting.....\")\n        if predict_proba:\n            print(\"#### Train AUC: \",roc_auc_score(y_train,clf.predict_proba(X_train)[:,1]))\n            pred = clf.predict_proba(X_val)[:,1]\n        \n        else:\n            print(\"#### Train AUC: \",roc_auc_score(y_train,clf.predict(X_train)))\n            pred = clf.predict(X_val)\n            \n        valpreds.append(pred)\n        valimagenames.append(image_names[idxV].values)\n        valtargets.append(y_val)\n\n        valauc = roc_auc_score(y_val,pred)\n        cvScore.append(valauc)\n        print(\"#### Val AUC: \",valauc)\n\n        print()\n    \n    valtargets = np.concatenate(valtargets)\n#     print(valtargets)\n    valpreds = np.concatenate(valpreds)\n#     print(valpreds)\n    valimagenames = np.concatenate(valimagenames)\n    \n    auc = roc_auc_score(valtargets,valpreds)\n    \n    print(f\"#### CV: {auc}\")\n    print(f\"#### Mean CV: {np.mean(cvScore)} +/- {np.std(cvScore)}\")\n    \n    oof = pd.DataFrame()\n    oof['image_name'] = valimagenames[:,0]\n    oof['pred'] = valpreds\n    oof['target'] = valtargets[:,0]\n    \n    sub = None\n    if predict_test:\n        clf = CLF(**params)\n        clf.fit(X,y)\n        \n        if predict_proba:\n            testpreds = clf.predict_proba(X_test)[:,1]\n        else:\n            testpreds = clf.predict(X_test)\n\n        \n        sub = pd.DataFrame(dict(image_name = test_base.image_name, target = testpreds))\n    \n    print(\"#\"*50)\n    \n    return cvScore, auc, oof, sub\n\n# if best_auc<auc:\n#     print(\"Score improved!!\")\n#     best_auc = auc\n# else:\n#     print(\"No improvement!!\")\n#     print(\"Best AUC: \",best_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLF = lgb.LGBMClassifier\nparams = dict(\n    boosting_type='gbdt',\n        num_leaves=31,\n        max_depth=3,\n        learning_rate=0.1,\n        n_estimators=110,\n        subsample_for_bin=200000,\n        objective=None,\n        class_weight=None,\n        min_split_gain=0.0,\n        min_child_weight=0.01,\n        min_child_samples=20,\n        subsample=0.9,\n        subsample_freq=0,\n        colsample_bytree=1.0,\n        reg_alpha=0.0,\n        reg_lambda=0.0,\n        random_state=SEED,\n        n_jobs=-1,\n        silent=True,\n        importance_type='split'\n)\n\ncvScore, auc, oof, testpreds = crossValidate(CLF=CLF,params=params,predict_test=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"??lgb.LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_clfs = [\n#     RidgeClassifier,\n#     Lasso,\n    KNeighborsClassifier,\n#     KNeighborsClassifier,\n#     KNeighborsClassifier,\n#     KNeighborsClassifier,\n#     KNeighborsClassifier,\n\n    RandomForestClassifier,\n#     RandomForestClassifier,\n#     RandomForestClassifier,\n#     RandomForestClassifier,\n#     RandomForestClassifier,\n    \n    GaussianNB,\n#     GaussianNB,\n#     GaussianNB,\n#     GaussianNB,\n#     GaussianNB,\n    \n    LogisticRegression,\n#     LogisticRegression,\n#     LogisticRegression,\n#     LogisticRegression,\n#     LogisticRegression,\n\n    \n    lgb.LGBMClassifier,\n#     lgb.LGBMClassifier,\n#     lgb.LGBMClassifier,\n#     lgb.LGBMClassifier,\n#     lgb.LGBMClassifier,\n]\n\nbase_params = [\n#     dict(\n#         alpha=0.5,\n#         fit_intercept=True,\n#         normalize=False,\n#         copy_X=True,\n#         max_iter=100,\n#         tol=0.001,\n#         class_weight=None,\n#         solver='auto',\n#         random_state=SEED\n#     ),\n    \n#     dict(\n#         alpha=0.5,\n#         fit_intercept=True,\n#         normalize=False,\n#         precompute=False,\n#         copy_X=True,\n#         max_iter=1000,\n#         tol=0.0001,\n#         warm_start=False,\n#         positive=False,\n#         selection='cyclic',\n#         random_state=SEED\n#     ),\n    \n    dict(\n        n_neighbors=200,\n        weights='uniform',\n        algorithm='auto',\n        leaf_size=30,\n        p=1,\n        metric='minkowski',\n        metric_params=None,\n        n_jobs=-1\n    ),\n#     dict(\n#         n_neighbors=70,\n#         weights='uniform',\n#         algorithm='auto',\n#         leaf_size=30,\n#         p=2,\n#         metric='minkowski',\n#         metric_params=None,\n#         n_jobs=-1\n#     ),\n#     dict(\n#         n_neighbors=80,\n#         weights='uniform',\n#         algorithm='auto',\n#         leaf_size=30,\n#         p=1,\n#         metric='minkowski',\n#         metric_params=None,\n#         n_jobs=-1\n#     ),\n#     dict(\n#         n_neighbors=80,\n#         weights='uniform',\n#         algorithm='auto',\n#         leaf_size=30,\n#         p=2,\n#         metric='minkowski',\n#         metric_params=None,\n#         n_jobs=-1\n#     ),\n#     dict(\n#         n_neighbors=90,\n#         weights='uniform',\n#         algorithm='auto',\n#         leaf_size=30,\n#         p=1,\n#         metric='minkowski',\n#         metric_params=None,\n#         n_jobs=-1\n#     ),\n    \n    dict(\n        n_estimators=90,\n        criterion='gini',\n        max_depth=5,\n        min_samples_split=3,\n        min_samples_leaf=1,\n        min_weight_fraction_leaf=0.0,\n        max_features='auto',\n        max_leaf_nodes=30,\n        min_impurity_decrease=0.0,\n        min_impurity_split=None,\n        bootstrap=True,\n        oob_score=False,\n        n_jobs=-1,\n        random_state=SEED,\n        verbose=0,\n        warm_start=False,\n        class_weight=None,\n        ccp_alpha=0.0,\n        max_samples=None,\n    ),\n#     dict(\n#         n_estimators=100,\n#         criterion='entropy',\n#         max_depth=3,\n#         min_samples_split=2,\n#         min_samples_leaf=1,\n#         min_weight_fraction_leaf=0.0,\n#         max_features='auto',\n#         max_leaf_nodes=None,\n#         min_impurity_decrease=0.0,\n#         min_impurity_split=None,\n#         bootstrap=True,\n#         oob_score=False,\n#         n_jobs=-1,\n#         random_state=SEED,\n#         verbose=0,\n#         warm_start=False,\n#         class_weight=None,\n#         ccp_alpha=0.0,\n#         max_samples=None,\n#     ),\n#     dict(\n#         n_estimators=100,\n#         criterion='gini',\n#         max_depth=5,\n#         min_samples_split=2,\n#         min_samples_leaf=1,\n#         min_weight_fraction_leaf=0.0,\n#         max_features='auto',\n#         max_leaf_nodes=None,\n#         min_impurity_decrease=0.0,\n#         min_impurity_split=None,\n#         bootstrap=True,\n#         oob_score=False,\n#         n_jobs=-1,\n#         random_state=SEED,\n#         verbose=0,\n#         warm_start=False,\n#         class_weight=None,\n#         ccp_alpha=0.0,\n#         max_samples=None,\n#     ),\n#     dict(\n#         n_estimators=100,\n#         criterion='entropy',\n#         max_depth=5,\n#         min_samples_split=2,\n#         min_samples_leaf=1,\n#         min_weight_fraction_leaf=0.0,\n#         max_features='auto',\n#         max_leaf_nodes=None,\n#         min_impurity_decrease=0.0,\n#         min_impurity_split=None,\n#         bootstrap=True,\n#         oob_score=False,\n#         n_jobs=-1,\n#         random_state=SEED,\n#         verbose=0,\n#         warm_start=False,\n#         class_weight=None,\n#         ccp_alpha=0.0,\n#         max_samples=None,\n#     ),\n#     dict(\n#         n_estimators=100,\n#         criterion='gini',\n#         max_depth=7,\n#         min_samples_split=2,\n#         min_samples_leaf=1,\n#         min_weight_fraction_leaf=0.0,\n#         max_features='auto',\n#         max_leaf_nodes=None,\n#         min_impurity_decrease=0.0,\n#         min_impurity_split=None,\n#         bootstrap=True,\n#         oob_score=False,\n#         n_jobs=-1,\n#         random_state=SEED,\n#         verbose=0,\n#         warm_start=False,\n#         class_weight=None,\n#         ccp_alpha=0.0,\n#         max_samples=None,\n#     ),\n    \n    dict(var_smoothing=1e-1),\n#     dict(var_smoothing=1e-8),\n#     dict(var_smoothing=1e-7),\n#     dict(var_smoothing=1e-6),\n#     dict(var_smoothing=1e-5),\n    \n    dict(\n        dual=False,\n        tol=0.0001,\n        C=1.0,\n        fit_intercept=True,\n        intercept_scaling=1,\n        class_weight=None,\n        random_state=SEED,\n        solver='lbfgs',\n        max_iter=100,\n        multi_class='auto',\n        verbose=0,\n        warm_start=False,\n        n_jobs=-1,\n        l1_ratio=None,\n    ),\n#     dict(\n#         penalty='l2',\n#         dual=False,\n#         tol=0.0001,\n#         C=0.01,\n#         fit_intercept=True,\n#         intercept_scaling=1,\n#         class_weight=None,\n#         random_state=SEED,\n#         solver='lbfgs',\n#         max_iter=100,\n#         multi_class='auto',\n#         verbose=0,\n#         warm_start=False,\n#         n_jobs=-1,\n#         l1_ratio=None,\n#     ),\n#     dict(\n#         penalty='l2',\n#         dual=False,\n#         tol=0.0001,\n#         C=0.001,\n#         fit_intercept=True,\n#         intercept_scaling=1,\n#         class_weight=None,\n#         random_state=SEED,\n#         solver='lbfgs',\n#         max_iter=100,\n#         multi_class='auto',\n#         verbose=0,\n#         warm_start=False,\n#         n_jobs=-1,\n#         l1_ratio=None,\n#     ),\n#     dict(\n#         penalty='l2',\n#         dual=False,\n#         tol=0.0001,\n#         C=0.0001,\n#         fit_intercept=True,\n#         intercept_scaling=1,\n#         class_weight=None,\n#         random_state=SEED,\n#         solver='lbfgs',\n#         max_iter=100,\n#         multi_class='auto',\n#         verbose=0,\n#         warm_start=False,\n#         n_jobs=-1,\n#         l1_ratio=None,\n#     ),\n#     dict(\n#         penalty='l2',\n#         dual=False,\n#         tol=0.0001,\n#         C=0.00001,\n#         fit_intercept=True,\n#         intercept_scaling=1,\n#         class_weight=None,\n#         random_state=SEED,\n#         solver='lbfgs',\n#         max_iter=100,\n#         multi_class='auto',\n#         verbose=0,\n#         warm_start=False,\n#         n_jobs=-1,\n#         l1_ratio=None,\n#     ),\n    \n    dict(\n        boosting_type='gbdt',\n        num_leaves=31,\n        max_depth=3,\n        learning_rate=0.1,\n        n_estimators=110,\n        subsample_for_bin=200000,\n        objective=None,\n        class_weight=None,\n        min_split_gain=0.0,\n        min_child_weight=0.01,\n        min_child_samples=20,\n        subsample=0.9,\n        subsample_freq=0,\n        colsample_bytree=1.0,\n        reg_alpha=0.0,\n        reg_lambda=0.0,\n        random_state=SEED,\n        n_jobs=-1,\n        silent=True,\n        importance_type='split'\n    ),\n#     dict(\n#         boosting_type='dart',\n#         num_leaves=31,\n#         max_depth=3,\n#         learning_rate=0.1,\n#         n_estimators=100,\n#         subsample_for_bin=200000,\n#         objective=None,\n#         class_weight=None,\n#         min_split_gain=0.0,\n#         min_child_weight=0.001,\n#         min_child_samples=20,\n#         subsample=1.0,\n#         subsample_freq=0,\n#         colsample_bytree=1.0,\n#         reg_alpha=0.0,\n#         reg_lambda=0.0,\n#         random_state=SEED,\n#         n_jobs=-1,\n#         silent=True,\n#         importance_type='split'\n#     ),\n#     dict(\n#         boosting_type='gbdt',\n#         num_leaves=31,\n#         max_depth=5,\n#         learning_rate=0.1,\n#         n_estimators=100,\n#         subsample_for_bin=200000,\n#         objective=None,\n#         class_weight=None,\n#         min_split_gain=0.0,\n#         min_child_weight=0.001,\n#         min_child_samples=20,\n#         subsample=1.0,\n#         subsample_freq=0,\n#         colsample_bytree=1.0,\n#         reg_alpha=0.0,\n#         reg_lambda=0.0,\n#         random_state=SEED,\n#         n_jobs=-1,\n#         silent=True,\n#         importance_type='split'\n#     ),\n#     dict(\n#         boosting_type='dart',\n#         num_leaves=31,\n#         max_depth=5,\n#         learning_rate=0.1,\n#         n_estimators=100,\n#         subsample_for_bin=200000,\n#         objective=None,\n#         class_weight=None,\n#         min_split_gain=0.0,\n#         min_child_weight=0.001,\n#         min_child_samples=20,\n#         subsample=1.0,\n#         subsample_freq=0,\n#         colsample_bytree=1.0,\n#         reg_alpha=0.0,\n#         reg_lambda=0.0,\n#         random_state=SEED,\n#         n_jobs=-1,\n#         silent=True,\n#         importance_type='split'\n#     ),\n#     dict(\n#         boosting_type='gbdt',\n#         num_leaves=31,\n#         max_depth=7,\n#         learning_rate=0.1,\n#         n_estimators=100,\n#         subsample_for_bin=200000,\n#         objective=None,\n#         class_weight=None,\n#         min_split_gain=0.0,\n#         min_child_weight=0.001,\n#         min_child_samples=20,\n#         subsample=1.0,\n#         subsample_freq=0,\n#         colsample_bytree=1.0,\n#         reg_alpha=0.0,\n#         reg_lambda=0.0,\n#         random_state=SEED,\n#         n_jobs=-1,\n#         silent=True,\n#         importance_type='split'\n#     ),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_meta = []\ntest_meta = []\nauc_meta = []\n\nfor params, clf in zip(base_params,base_clfs):\n    \n    cvScore, auc, oof, testpreds = crossValidate(CLF=clf,params=params,predict_test=True)\n    \n    train_meta.append(oof)\n    test_meta.append(testpreds)\n    auc_meta.append(auc)\n\nprint()\nprint()\nprint(\"#### AUCs: \", auc_meta)\nprint(f\"#### Mean AUC: {np.mean(auc_meta)} +/- {np.std(auc_meta)}\")\nprint()\nprint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0.945737877503331 +/- 0.006461139964516082","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_clf = LogisticRegression\nmeta_params = dict(\n        penalty='l2',\n        dual=False,\n        tol=0.0001,\n        C=0.01,\n        fit_intercept=True,\n        intercept_scaling=1,\n        class_weight=None,\n        random_state=SEED,\n        solver='lbfgs',\n        max_iter=100,\n        multi_class='auto',\n        verbose=0,\n        warm_start=False,\n        n_jobs=-1,\n        l1_ratio=None,\n    )\n# meta_clf = XGBClassifier\n# meta_params = dict(\n#     base_score=0.5,\n#     booster='gbtree',\n#     colsample_bylevel=0.7,\n#     colsample_bynode=0.7,\n#     colsample_bytree=0.7,\n#     gamma=0,\n#     gpu_id=-1,\n#     importance_type='gain',\n#     interaction_constraints='',\n#     learning_rate=0.00300000012,\n#     max_delta_step=0,\n#     max_depth=5,\n#     min_child_weight=1,\n#     monotone_constraints='()',\n#     n_estimators=100,\n#     n_jobs=-1,\n#     num_parallel_tree=1,\n#     objective='binary:logistic',\n#     random_state=SEED,\n#     reg_alpha=0,\n#     reg_lambda=0,\n#     scale_pos_weight=1,\n#     subsample=1,\n#     tree_method='exact',\n#     validate_parameters=1,\n#     verbosity=0\n# )\n\nX_meta = train_meta[0]\nX_test_meta = test_meta[0]\n\nfor i, oof in enumerate(train_meta[1:]):\n    X_meta = X_meta.merge(oof[['image_name','pred']],on='image_name',suffixes=(f'_{i}',f'_{i+1}'))\n\nfor i, testpreds in enumerate(test_meta[1:]):\n    X_test_meta = X_test_meta.merge(testpreds,on='image_name',suffixes=(f'_{i}',f'_{i+1}'))\n    \nX_meta = X_meta.merge(oof_base[['image_name','tfrecord']],on='image_name')\n\nX_ = X_meta.drop(['image_name','target','tfrecord'],axis=1)\ny_ = X_meta[['target']]\nX_test_ = X_test_meta.drop(['image_name'],axis=1)\ntfrecord_ = X_meta[['tfrecord']]\nimage_names_ = X_meta[['image_name']]\n\nX_test_.columns = X_.columns\n\ncvScore, auc, oof, testpreds = crossValidate(X=X_,y=y_,\n                                             X_test=X_test_,\n                                             tfrecord=tfrecord_,\n                                             image_names=image_names_,\n                                             skf=skf,\n                                             CLF=meta_clf,\n                                             params=meta_params,\n                                             predict_test=True,\n                                             predict_proba=True\n                                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(oof.pred,bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testpreds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(testpreds.target,bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testpreds.to_csv(f'TESTPREDS_STACKING_{auc}.csv',index=False)\noof.to_csv(f'oof_stacking_{auc}.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}